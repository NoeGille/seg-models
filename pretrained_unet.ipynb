{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install carbontracker\n",
    "#!pip install albumentations==1.3.0\n",
    "#!pip install timm\n",
    "#!pip install segmentation-models-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\noegi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dataset_florian import FashionMNISTDataset, FashionMNISTDatasetRGB\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import matplotlib.pyplot as plt\n",
    "from models import UNet, UNETR\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import wandb\n",
    "from carbontracker.tracker import CarbonTracker\n",
    "import segmentation_models_pytorch as smp\n",
    "from metrics import LossManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters:  23749546\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/438 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'valid_img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 46\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[39mfor\u001b[39;00m img, mask \u001b[39min\u001b[39;00m tqdm(train_dataloader):\n\u001b[0;32m     45\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m---> 46\u001b[0m         valid_img \u001b[39m=\u001b[39m valid_img\u001b[39m.\u001b[39mto(device\u001b[39m=\u001b[39mDEVICE)\n\u001b[0;32m     47\u001b[0m         valid_mask \u001b[39m=\u001b[39m valid_mask\u001b[39m.\u001b[39mto(device\u001b[39m=\u001b[39mDEVICE)\n\u001b[0;32m     49\u001b[0m         loss \u001b[39m=\u001b[39m criterion(model(valid_img), valid_mask)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'valid_img' is not defined"
     ]
    }
   ],
   "source": [
    "# CONSTANTS\n",
    "\n",
    "DATASET_PATH = 'datasets/'\n",
    "MODEL_PATH = 'models/'\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "NUM_CLASSES = 10\n",
    "BATCH_SIZE = 16\n",
    "INPUT_SIZE = (224, 224, 1)\n",
    "\n",
    "kwargs = {'encoder_name':'vgg16',        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    'encoder_weights': None,     # use `imagenet` pre-trained weights for encoder initialization\n",
    "    'in_channels':3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    'classes':10,                      # model output channels (number of classes in your dataset)\n",
    "}\n",
    "\n",
    "model = smp.Unet(**kwargs).to(DEVICE)\n",
    "model.train()\n",
    "dataset_name = 'data_rgb_b_noise_len_10k'\n",
    "# LOAD DATASET\n",
    "train_dataset = torch.load(DATASET_PATH + 'train_' + dataset_name + '.pt')\n",
    "valid_dataset = torch.load(DATASET_PATH + 'valid_' + dataset_name + '.pt')\n",
    "\n",
    "# Traininig and validation dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Training\n",
    "\n",
    "LEARNING_RATE = 0.0001\n",
    "EPOCHS = 20\n",
    "model_name = 'unet_unetr_lr_loss'\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "print(\"Number of parameters: \", sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "\n",
    "loss_manager = LossManager()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    print(f'Epoch {epoch +1}/{EPOCHS}')\n",
    "    for (train_img, train_mask), (valid_img, valid_mask) in tqdm(zip(train_dataloader, valid_dataloader)):\n",
    "        # Calculate loss on validation set\n",
    "        if validation_loss:\n",
    "            with torch.no_grad():\n",
    "                valid_img = valid_img.to(device=DEVICE)\n",
    "                valid_mask = valid_mask.to(device=DEVICE)\n",
    "                \n",
    "                loss = criterion(model(valid_img), valid_mask)\n",
    "                loss_manager.add(loss.item())\n",
    "\n",
    "        train_img = train_img.to(device=DEVICE)\n",
    "        train_mask = train_mask.to(device=DEVICE) # dim : (batch_size, 224, 224)\n",
    "        # prediction\n",
    "        mask_pred = model(train_img)  # dim : (batch_size, 10, 224, 224)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(mask_pred, train_mask)\n",
    "            \n",
    "            \n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # gradient descent or adam step\n",
    "        optimizer.step()\n",
    "\n",
    "    #tracker.epoch_end()\n",
    "    print(f'Loss: {loss.item()}')\n",
    "    loss_manager.epoch_end()\n",
    "\n",
    "torch.save(\n",
    "    {   \n",
    "        'input_size':INPUT_SIZE,\n",
    "        'epochs':EPOCHS,\n",
    "        'learning_rate':LEARNING_RATE,\n",
    "        'batch_size':BATCH_SIZE,\n",
    "        'num_classes':NUM_CLASSES,\n",
    "        'model_state_dict':model.state_dict(),\n",
    "        'optimizer_state_dict':optimizer.state_dict(),\n",
    "        'loss':loss,\n",
    "        'datasets': dataset_name,\n",
    "        'model_class': smp.Unet,\n",
    "        'kwargs':kwargs\n",
    "        }, MODEL_PATH + model_name + '.pt'\n",
    "    )\n",
    "file = open('results/loss/' + f'{model_name}_loss.txt', 'w')\n",
    "for elt in loss_manager.losses:\n",
    "    file.write(str(float(elt)) + '\\n')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
